- Output of FFT is in whole number frequencies where as musical notes usually have decimal points
the difference matters less as pitch increases( at ~ 500Hz it becomes difficult to tell ) but, 
in the effort of creating a bass pedal, this will matter.

- In light of the above, I will be using librosa's stft as the main engine for input processing instead
- Music Information Retrieval

- The input preprocessing pipeline has been established. The STFT of the input and target files are created and stored as text
- Embedding Python in C++ code has been implemented, this will be used to take advantage of librosa from c++.
- Several functions for dealing with numpy arrays( stored as text ) have been implemented for c++.

- I've modified the neural network code from in class and cleaned it up.

- I successfully passed an audio file through the network and reconstructed it without loss.
The network was set to not modify the input.

- The project architecture was tuned so that all STFTs can be applied before running the network, the network
now operates directly on the STFT values.

- I successfully passed audio through the network, modifying it in the process.

- The fitness function and EA were implemented and a network was evolved to try and add the first harmonic
- The initial results are very promising. Using 100 individuals and 50 generations, the network was able to 
generate a fuzzy sounding first harmonic on the diatonic note just above the target( The target is E2 and E3 and the network
generated F#2 and F#3 ) The runs took about 5 minute each.

- The current network architecture is one layer of 1025 inputs directly connected to 1025 outputs. Each neuron uses
a leaky relu activation function.

- The next step is to implement a CPPN and see how that affects performance.